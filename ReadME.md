# 大鱼AI🐟 ：李宏毅机器学习(台湾大学)


## 课程资料
1. [课程主页](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML17_2.html)  
2. [课程笔记](https://blog.csdn.net/dukuku5038/article/details/82253966)  
3. [课程视频](https://www.bilibili.com/video/av10590361?from=search&seid=8516959386096686045)  
4. [环境配置Anaconda](https://github.com/learning511/Stanford-Machine-Learning-camp/tree/master)
5. [作业介绍]() 
6. 比赛环境推荐使用Linux或者Mac系统，以下环境搭建方法皆适用:  
    [Docker环境配置](https://github.com/ufoym/deepo)  
    [本地环境配置](https://github.com/learning511/cs224n-learning-camp/blob/master/environment.md)


## 重要一些的资源：
1. [深度学习经典论文](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap.git)
2. [深度学习斯坦福教程](http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B)
3. [廖雪峰python3教程](https://www.liaoxuefeng.com/article/001432619295115c918a094d8954bd493037b03d27bf9a9000)
4. [github教程](https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)
5. [莫烦机器学习教程](https://morvanzhou.github.io/tutorials)
6. [深度学习经典论文](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap.git)
7. [机器学习代码修行100天](https://github.com/Avik-Jain/100-Days-Of-ML-Code)  
8. [吴恩达机器学习新书：machine learning yearning](https://github.com/AcceptedDoge/machine-learning-yearning-cn)  
9. [本人博客(深度学习专题)](https://blog.csdn.net/column/details/28693.html)  
10. [自上而下的学习路线: 软件工程师的机器学习](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-CN.md)  


## 1. 前言 
### 中文世界中最好的机器学习课程！

李宏毅老师的机器学习和深度学习系列课程，是中文世界中最好！课程中有深入浅出的讲解和幽默生动的比喻（还有口袋妖怪哦）。关键一切都是中文的！


本课程李宏毅老师的机器学习核心内容带学，作业讲解。主要包括：

（一）监督学习（回归、分类、BP反向传播、梯度下降）

（二）无监督学习（AutoEncoder、Neighbor Embedding、Deep Generative Model）

（三）迁移学习 （Transfer learning）

 (四) 结构化学习（Structure learning）
 
本课程每课都有课件，每周都有配套作业代码，十分推荐推荐学习。

## 2.数学知识复习  
1.[线性代数](http://web.stanford.edu/class/cs224n/readings/cs229-linalg.pdf)  
2.[概率论](http://web.stanford.edu/class/cs224n/readings/cs229-prob.pdf)  
3.[凸函数优化](http://web.stanford.edu/class/cs224n/readings/cs229-cvxopt.pdf)  
4.[随机梯度下降算法](http://cs231n.github.io/optimization-1/)  

#### 中文资料：    
- [机器学习中的数学基本知识](https://www.cnblogs.com/steven-yang/p/6348112.html)  
- [统计学习方法](http://vdisk.weibo.com/s/vfFpMc1YgPOr)  
**大学数学课本（从故纸堆里翻出来^_^）**  

### 3.编程工具 
#### 斯坦福资料： 
- [Python复习](http://web.stanford.edu/class/cs224n/lectures/python-review.pdf)  

#### 4. 中文书籍推荐：
- 《机器学习》周志华  

- 《统计学习方法》李航  

- 《机器学习课》邹博  

## 5. 学习安排
本课程需要11周共18节课，
每周具体时间划分为4个部分:  
- 1部分安排周一到周二  
- 2部分安排在周四到周五  
- 3部分安排在周日  
- 4部分作业是本周任何时候空余时间    
- 周日晚上提交作业运行截图  
- 周三、周六休息^_^  

#### 6.作业提交指南：  
 训练营的作业自检系统已经正式上线啦！只需将作业发送到训练营公共邮箱即可，知识星球以打卡为主，不用提交作业。以下为注意事项:  
<0> 课程资料：[链接]() 密码：
<1> 训练营代码公共邮箱：NTU-ML@xx.com  
<2> [查询自己成绩:]()  
<3> 将每周作业压缩成zip文件，文件名为“学号+作业编号”，例如："NTU-ML-010037-01.zip"  
<4> 注意不要改变作业中的"方法名","类名"不然会检测失败！！ 

## 7.学习安排
### week 1  
**知识点复习**  
**学习组队**  
**第1节： 引言(Introduction)**  
**课件：**[lecture1](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture1.pdf)  
**笔记：**[lecture1-note1](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture1.pdf)  
**视频：**  
	1.1 欢迎:[Welcome to Machine Learning](https://www.bilibili.com/video/av10590361/?p=1)  
	1.2 为什么要学习机器学习？:[Why learning ？](https://www.bilibili.com/video/av10590361/?p=2)  
**作业 Week1：**:  
制定自己的学习计划，开通自己的学习博客，注册自己的github  

### week 2 
**第2节： 回归问题**  
**课件：**[lecture2]()  
**笔记：**[lecture2-note2]()  
**视频：**  
	2.1 回归:[Regression](https://www.bilibili.com/video/av10590361/?p=3)  
	2.2 回归 Demo:[Demo](https://www.bilibili.com/video/av9912938/?p=4)  

**第3节： 错误分析**  
**课件：**[lecture3]()  
**笔记：**[lecture3-note3]()  
**视频：**    
	2.3 错误从哪里来[Error Handle](https://www.bilibili.com/video/av10590361/?p=5)  
**作业 Week2：**:  
  [PM2.5 预测](https://ntumlta.github.io/2017fall-ml-hw1/)  
---------------------------------------------------------
### week 3   
**第4节： 梯度下降(Gradient Descent )**  
**课件：**[lecture4]()  
**笔记：**[lecture4-note4]()  
**视频：**  
	3.1梯度下降:[Gradient Descent](https://www.bilibili.com/video/av10590361/?p=6)  
	3.2梯度下降Demo1:[Gradient Descent Demo1](https://www.bilibili.com/video/av10590361/?p=6)  
	3.3梯度下降Demo2:[Gradient Descent Demo2](https://www.bilibili.com/video/av10590361/?p=6)  
	3.4矩阵乘法:[Matrix Matrix Multiplication](https://www.bilibili.com/video/av9912938/?p=16)  

**作业 Week3：**:  
  [PM2.5 预测](https://ntumlta.github.io/2017fall-ml-hw1/)  

---------------------------------------------------------

### Week 4  
**第5节：分类：概率生成模型（Classification：Probabilistic Generative Model）**  
**课件：**[lecture5]()  
**笔记：**[lecture5-note5]()  
**视频：**  
	4.1分类：概率生成模型:[Classification：Probabilistic Generative Model](https://www.bilibili.com/video/av10590361/?p=10)  
	
**第6节：分类：逻辑回归（Logistic Regression）**  
**课件：**[lecture6]()  
**笔记：**[lecture6-note6]()  
**视频：**  
	4.2分类：逻辑回归:[Logistic Regression](https://www.bilibili.com/video/av10590361/?p=11)   

**作业 Week4：**: [ Winner or Loser](https://ntumlta.github.io/2017fall-ml-hw2)  

---------------------------------------------------------

### Week 5     
**第7节：深度学习简介(Introduction to Deep learning)**  
**课件：**[lecture7]()  
**笔记：**[lecture7-note7]()  
**视频：**                                  
	5.1 度学习简介:[Introduction to Deep learning](https://www.bilibili.com/video/av10590361/?p=13)  
	5.2 反向传播算法：[Back Prppagation](https://www.bilibili.com/video/av10590361/?p=14))  

**第8节：“Hello world” of Deep learning*  
**课件：**[lecture8]()  
**笔记：**[lecture8-note8]()  
**视频：**                                  
	5.1 [DeepLearning Demo](https://www.bilibili.com/video/av10590361/?p=15)  
	5.2  Keras Demo：[Demo](https://www.bilibili.com/video/av10590361/?p=16)  
	5.2  Keras Demo1：[Demo1](https://www.bilibili.com/video/av10590361/?p=17)  
	
**第9节：深度学习技巧 Deep learning tips*  
**课件：**[lecture9]()  
**笔记：**[lecture8-note9]()  
**视频：**                                  
	5.3 [DeepLearning tips](https://www.bilibili.com/video/av10590361/?p=18)  
	5.4  Keras Demo2：[Demo2](https://www.bilibili.com/video/av10590361/?p=19)  
		
**作业 Week5：**: 图片分类[Image Classification](https://ntumlta.github.io/ML-Assignment3/index.html))  

---------------------------------------------------------
   

### Week 6  
**第九节1：神经网络的学习(Neural Networks: Learning1)**  
**课件：**[lecture9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture9.pdf)  
**笔记：**[lecture9-note9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture9.pdf)   
**视频：**   
	9.1代价函数:[Cost Function](https://www.bilibili.com/video/av9912938/?p=51)  
	9.2反向传播算法:[Backpropagation Algorithm](https://www.bilibili.com/video/av9912938/?p=52)  
	9.3反向传播算法的直观理解:[Backpropagation Intuition](https://www.bilibili.com/video/av9912938/?p=53)  

**第九节2：神经网络的学习(Neural Networks: Learning2)**  
**课件：**[lecture9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture9.pdf)  
**笔记：**[lecture9-note9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture9.pdf)  
**视频：**   
	9.4实现注意：展开参数:[Implementation Note_ Unrolling Parameters](https://www.bilibili.com/video/av9912938/?p=54)  
	9.5梯度检验:[Gradient Checking](https://www.bilibili.com/video/av9912938/?p=55)  
	9.6随机初始化:[Random Initialization](https://www.bilibili.com/video/av9912938/?p=56)  
	9.7综合起来:[Putting It Together](https://www.bilibili.com/video/av9912938/?p=57)  
	9.8自主驾驶:[Autonomous Driving](https://www.bilibili.com/video/av9912938/?p=58)  

**作业 Week6：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex4/ex4.pdf)  
1. 神经网络实现 Neural Networks Learning  

---------------------------------------------------------

### Week 7  
**第十节：应用机器学习的建议(Advice for Applying Machine Learning)**  
**课件：**[lecture10](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture10.pdf)  
**笔记：**[lecture10-note10](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture10.pdf)  
**视频：**  
	10.1决定下一步做什么:[Deciding What to Try Next](https://www.bilibili.com/video/av9912938/?p=59)  
	10.2评估一个假设:[Evaluating a Hypothesis](https://www.bilibili.com/video/av9912938/?p=60)  
	10.3模型选择和交叉验证集:[Model Selection and Train_Validation_Test Sets](https://www.bilibili.com/video/av9912938/?p=61)  
	10.4诊断偏差和方差:[Diagnosing Bias vs. Variance](https://www.bilibili.com/video/av9912938/?p=62)  
	10.5正则化和偏差/方差:[Regularization and Bias_Variance](https://www.bilibili.com/video/av9912938/?p=63)  
	10.6学习曲线:[Learning Curves](https://www.bilibili.com/video/av9912938/?p=64)  
	10.7决定下一步做什么:[Deciding What to Do Next Revisited](https://www.bilibili.com/video/av9912938/?p=65)                                        
**第十一节：  机器学习系统的设计(Machine Learning System Design)**  
**课件：**[lecture11](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture11.pdf)  
**笔记：**[lecture11-note11](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture11.pdf)  
**视频：**  
	11.1首先要做什么:[Prioritizing What to Work On](https://www.bilibili.com/video/av9912938/?p=66)  
	11.2误差分析:[Error Analysis](https://www.bilibili.com/video/av9912938/?p=67)  
	11.3类偏斜的误差度量:[Error Metrics for Skewed Classes](https://www.bilibili.com/video/av9912938/?p=68)  
	11.4查准率和查全率之间的权衡:[Trading Off Precision and Recall](https://www.bilibili.com/video/av9912938/?p=69)  
	11.5机器学习的数据:[Data For Machine Learning](https://www.bilibili.com/video/av9912938/?p=70)  
**作业 Week7：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex5/ex5.pdf)  
1. 正则线性回归 Regularized Linear Regression  
2. 偏移和方差 Bias vs. Variance  

---------------------------------------------------------

### Week 8  
**第十二节：支持向量机(Support Vector Machines)**  
**课件：**[lecture12](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture12.pdf)  
**笔记：**[lecture12-note12](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture12.pdf)  
**视频：**  
	12.1优化目标:[Optimization Objective](https://www.bilibili.com/video/av9912938/?p=71)  
	12.2大边界的直观理解:[Large Margin Intuition](https://www.bilibili.com/video/av9912938/?p=72)  
	12.3数学背后的大边界分类（选修）:[Mathematics Behind Large Margin Classification (Optional)](https://www.bilibili.com/video/av9912938/?p=73)  
	12.4核函数1:[Kernels I](https://www.bilibili.com/video/av9912938/?p=74)  
	12.5核函数2:[Kernels II](https://www.bilibili.com/video/av9912938/?p=75)  
	12.6使用支持向量机:[Using An SVM](https://www.bilibili.com/video/av9912938/?p=76)  

**第十三节：聚类(Clustering)**  
**课件：**[lecture13](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture13.pdf)  
**笔记：**[lecture13-note13](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture13.pdf)  
**视频：**   
	13.1无监督学习：简介:[Unsupervised Learning_ Introduction](https://www.bilibili.com/video/av9912938/?p=77)  
	13.2K-均值算法:[K-Means Algorithm](https://www.bilibili.com/video/av9912938/?p=78)  
	13.3优化目标:[Optimization Objective](https://www.bilibili.com/video/av9912938/?p=79)  
	13.4随机初始化:[Random Initialization](https://www.bilibili.com/video/av9912938/?p=80)  
	13.5选择聚类数:[Choosing the Number of Clusters](https://www.bilibili.com/video/av9912938/?p=81)  
**作业 Week8：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex6/ex6.pdf)  
1. SVM实现
2. 垃圾邮件分类 Spam email Classifier  

---------------------------------------------------------

### Week 9
**第十四节：降维(Dimensionality Reduction)**  
**课件：**[lecture14](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture14.pdf)  
**笔记：**[lecture14-note14](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture14.pdf)  
**视频：**     
	14.1动机一：数据压缩:[Motivation I_ Data Compression](https://www.bilibili.com/video/av9912938/?p=82)  
	14.2动机二：数据可视化:[Motivation II_ Visualization](https://www.bilibili.com/video/av9912938/?p=83)  
	14.3主成分分析问题:[Principal Component Analysis Problem Formulation](https://www.bilibili.com/video/av9912938/?p=84)  
	14.4主成分分析算法:[Principal Component Analysis Algorithm](https://www.bilibili.com/video/av9912938/?p=85)  
	14.5选择主成分的数量:[Choosing the Number of Principal Components](https://www.bilibili.com/video/av9912938/?p=86)  
	14.6重建的压缩表示:[Reconstruction from Compressed Representation](https://www.bilibili.com/video/av9912938/?p=87)  
	14.7主成分分析法的应用建议:[Advice for Applying PCA](https://www.bilibili.com/video/av9912938/?p=88)  

**第十五节：异常检测(Anomaly Detection)**  
**课件：**[lecture15](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture15.pdf)  
**笔记：**[lecture15-note15](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture15.pdf)  
**视频：**   
	15.1问题的动机:[Problem Motivation](https://www.bilibili.com/video/av9912938/?p=89)  
	15.2高斯分布:[Gaussian Distribution](https://www.bilibili.com/video/av9912938/?p=90)  
	15.3算法:[Algorithm](https://www.bilibili.com/video/av9912938/?p=91)  
	15.4开发和评价一个异常检测系统:[Developing and Evaluating an Anomaly Detection System](https://www.bilibili.com/video/av9912938/?p=92)  
	15.5异常检测与监督学习对比:[Anomaly Detection vs. Supervised Learning](https://www.bilibili.com/video/av9912938/?p=93)  
	15.6选择特征:[Choosing What Features to Use](https://www.bilibili.com/video/av9912938/?p=94)  
	15.7多元高斯分布（选修）:[Multivariate Gaussian Distribution (Optional)](https://www.bilibili.com/video/av9912938/?p=95)  
	15.8使用多元高斯分布进行异常检测（选修）:[Anomaly Detection using the Multivariate Gaussian Distribution (Optiona](https://www.bilibili.com/video/av9912938/?p=96)  
**作业 Week9：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex7/ex7.pdf)  
1. K-means 聚类算法 Clustering  
2. PCA 主成分析 Principal Component Analysis  

---------------------------------------------------------


### Week 10  
**第十六节：推荐系统(Recommender Systems)**  
**课件：**[lecture16](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture16.pdf)  
**笔记：**[lecture16-note16](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture16.pdf)  
**视频：**  
	16.1问题形式化:[Problem Formulation](https://www.bilibili.com/video/av9912938/?p=97)  
	16.2基于内容的推荐系统:[Content Based Recommendations](https://www.bilibili.com/video/av9912938/?p=98)  
	16.3协同过滤:[Collaborative Filtering](https://www.bilibili.com/video/av9912938/?p=99)  
	16.4协同过滤算法:[Collaborative Filtering Algorithm](https://www.bilibili.com/video/av9912938/?p=100)  
	16.5向量化：低秩矩阵分解:[Vectorization_ Low Rank Matrix Factorization](https://www.bilibili.com/video/av9912938/?p=101)  
	16.6推行工作上的细节：均值归一化:[Implementational Detail_ Mean Normalization](https://www.bilibili.com/video/av9912938/?p=102)  

**第十七节：大规模机器学习(Large Scale Machine Learning)**  
**课件：**[lecture17](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture17.pdf)  
**笔记：**[lecture17-note17](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture17.pdf))  
**视频：**  
	17.1大型数据集的学习:[Learning With Large Datasets](https://www.bilibili.com/video/av9912938/?p=103)  
	17.2随机梯度下降法:[Stochastic Gradient Descent](https://www.bilibili.com/video/av9912938/?p=104)  
	17.3小批量梯度下降:[Mini-Batch Gradient Descent](https://www.bilibili.com/video/av9912938/?p=105)  
	17.4随机梯度下降收敛:[Stochastic Gradient Descent Convergence](https://www.bilibili.com/video/av9912938/?p=106)  
	17.5在线学习:[Online Learning](https://www.bilibili.com/video/av9912938/?p=107)  
	17.6映射化简和数据并行:[Map Reduce and Data Parallelism](https://www.bilibili.com/video/av9912938/?p=108)  

**作业 Week10：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex8/ex8.pdf)  
  
1. 异常检测 Anomaly Detection    

---------------------------------------------------------


### Week 11  
**第十八节1： 应用实例：图片文字识别(Application Example: Photo OCR)**  
**课件：**[lecture18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture18.pdf)  
**笔记：**[lecture18-note18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture18.pdf)  
**视频：**  
	18.1问题描述和流程图:[Problem Description and Pipeline](https://www.bilibili.com/video/av9912938/?p=109)  
	18.2滑动窗口:[Sliding Windows](https://www.bilibili.com/video/av9912938/?p=110)   
**第十八节2： 应用实例：图片文字识别(Application Example: Photo OCR)**  
**课件：**[lecture18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture18.pdf)  
**笔记：**[lecture1-note18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture18.pdf))  
**视频：**   
	18.3获取大量数据和人工数据:[Getting Lots of Data and Artificial Data](https://www.bilibili.com/video/av9912938/?p=111)  
	18.4上限分析：哪部分管道的接下去做:[Ceiling Analysis_ What Part of the Pipeline to Work on Next](https://www.bilibili.com/video/av9912938/?p=112)  


**作业 Week11：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex8/ex8.pdf)  
2.推荐系统实现 Recommender Systems  
**课程比赛：比赛介绍: Kaggle 比赛： 泰坦尼克 Titanic**  

---------------------------------------------------------

### Week 12
**第十九节：总结(Conclusion)**  
**视频：**  
19.1总结和致谢:[Summary and Thank You](https://www.bilibili.com/video/av9912938/?p=113)  
**课程比赛：比赛: **  
 Kaggle 比赛： 泰坦尼克 Titanic
 
 
 ---------------------------------------------------------
